### Add from top:

22 May 27b:
So, things got too messy with the below approach, so to simplify self assessment, I assumed
that you only know your own effort, and you assume every fish you meet is average size and effort.
This actually seems to work pretty well. With pure SA, you get nice, correct hierarchies (assuming size 
matters somewhat). The function is set up so that you *could* use additional info if you wanted to, 
although I haven't tested that yet. 

22 May 27:
I got back into the likelihood function, and boy is that a mess. 
So it's probably not very reasonable to say that fish know exactly the size of their opponent, especially
if we're doing a Self Assessment model. So in that case, what do fish know? 
    My assumptions are that they know Own Effort, and the Opponent Wager. 
So that's pretty good, and then you can just infer your size based on those two things, EXCEPT!! The 
size variable that goes into determining the fight is relative size. So in order to do a likelihood function
of relative size, you need to know something about the size of the opponent (or the effort). 

I think the most reasonable assumption to make there is that in pure self assessment, you assume average
effort by the other fish. So I set effort to .5, and then infer the size of the opponent from that and then 
calculate a likelihood function for relative size in that way. This is basically a transformation of my size
to relative size for that fight. Obviously, if you know the opponent's size, this is much easier (and I should
probably update that as well eventually...). 

So in summary, under SA, fish base their likelihood functions from their known effort, the assumed effort of the opponent, and the experienced wager from the opponent.

Even this is a little weird, like you only really know that the opponent wagered as much as or more than you...
but this feels fine for now. Definitely something to think about. 

I think in the long run, we'll have these general predictions, and then we'll see what it takes to fit the data, and then we'll ask if such a model is biologically plausible. 

22 May 26:
Did a lot of work to get Hock-Huber approach working. I made a slight modification to the way they calculate probability so that it matches
the more empirically driven idea of the outcome being decided by the percent difference, with marginal effort having a bigger impact when 
you're close to the opponent's investment. 

I also brought it into my wager function, so that I could play with the amount of luck involved, as well as add a size component (by default, 
Hock assumed l=0.5, which is a linear relationship between relative effort and probability of winning)

Surprisingly, although the stability of the hock estimate swings widely, as I would have guessed, the stability of fights is fairly comparable. 
The caveat here is I still don't entirely trust my stability metric...so I should check on that next. 
On top of that, I should probably calculate the strength of the winner effect: i.e. the increased probability of winning following a win. 


22 May 25:
Ran all the simulations, things are looking quite good. Ended with running Hock approach
One thing to keep in mind here is that "stability" measures fight performance, while "estimate" measures internal state. 
So when I'm plotting the est_history, I'm plotting their internal states, while stability is based on their wins/losses. 

In any case, it does seem like Hock is a lot less stable, but that could be in part just because of the inherent luck in the approach. 
The next thing to do in order for a fair comparison is to build hock-huber into my existing 'mathy' approach. 
This will allow me to control the role of luck, to compare apples to apples. It will even let me bring in skill, to fully explore the space. 

I'll also need to come up with the naive winner effects: a n-round boost to estimate, or simple jump in estimate (either additive, or a scale factor)
Once that's done, I can make some contrasting predictions on behavior. 

Keep in mind that Bayes should be the ideal solution to this problem, so the question is whether it is feasible, and whether it's 
actually that much better than a very simple heuristic. 

The other thing to think about is the likelihood function, since that could also be explored. 

